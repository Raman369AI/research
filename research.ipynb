{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mh.txt') as f:\n",
    "    data = f.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "import random\n",
    "import en_core_web_trf\n",
    "from pprint import pprint\n",
    "from lmqg import TransformersQG\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "class MCQGeneration:\n",
    "    def __init__(self, file):\n",
    "        # Initialize model and embeddings\n",
    "        self.model = TransformersQG(model=\"lmqg/t5-base-squad-qag\")\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.persons = []\n",
    "\n",
    "        # Load SpaCy model (ensure it's installed)\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
    "        except OSError:\n",
    "            print(\"Downloading SpaCy model 'en_core_web_trf'...\")\n",
    "            from spacy.cli import download\n",
    "            download(\"en_core_web_trf\")\n",
    "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "        # Read input file\n",
    "        with open(file, \"r\") as f:\n",
    "            self.data = f.read()\n",
    "\n",
    "    def ner_extraction(self):\n",
    "        \"\"\"Extract named entities and generate documents.\"\"\"\n",
    "        doc = self.nlp(self.data)\n",
    "        words = defaultdict(set)\n",
    "\n",
    "        # Extract entities from sentences\n",
    "        for sent in doc.sents:\n",
    "            for ent in sent.ents:\n",
    "                words[ent.text].add((ent.text, sent.text, ent.label_))\n",
    "\n",
    "        context_answers = [item for value in words.values() for item in value]\n",
    "        persons = [(i[1], i[0], i[2]) for i in context_answers]\n",
    "\n",
    "        # Create documents with metadata\n",
    "        documents = [\n",
    "            Document(page_content=context, metadata={\"ner_tag\": ner_tag, \"class\": label})\n",
    "            for context, ner_tag, label in persons\n",
    "        ]\n",
    "        return documents, persons\n",
    "\n",
    "    def search(self, documents, persons):\n",
    "        \"\"\"Perform similarity search and generate MCQs.\"\"\"\n",
    "        docsearch = Chroma.from_documents(documents, self.embeddings)\n",
    "        print(\"Documents ingested successfully!\")\n",
    "\n",
    "        for doc in documents:\n",
    "            query = doc.page_content\n",
    "            results = docsearch.similarity_search(query)\n",
    "            linked = {}\n",
    "            question_answer = self.model.generate_qa(query)\n",
    "\n",
    "            # Use a temporary dictionary to avoid modifying during iteration\n",
    "            temp_linked = {}\n",
    "            for i in question_answer:\n",
    "                linked[i] = i\n",
    "                temp_linked[i] = i\n",
    "\n",
    "            for keys, values in temp_linked.items():\n",
    "                query = values[0]\n",
    "                ner = values[1]\n",
    "\n",
    "                # Filter persons based on NER tag\n",
    "                x = [j[2] for j in persons if j[1] == ner]\n",
    "\n",
    "                results = docsearch.similarity_search(query, k=100)  # Retrieve top-100 results\n",
    "                options = []\n",
    "\n",
    "                for result in results:\n",
    "                    print(result.metadata.get(\"class\"))\n",
    "                    if result.metadata.get(\"class\") in x:\n",
    "                        options.append(result.metadata.get(\"ner_tag\"))\n",
    "\n",
    "                # Handle cases where fewer than 3 options are available\n",
    "                if len(options) < 3:\n",
    "                    options += [None] * (3 - len(options))  # Pad with None if not enough options\n",
    "\n",
    "                if len(options) >= 3:  # Ensure there are enough options to sample from\n",
    "                    random_values = random.sample(options, 3)\n",
    "                    random_values.append(question_answer[0][1])  # Add the correct answer\n",
    "                    random.shuffle(random_values)  # Shuffle the options\n",
    "                    linked[\"options\"] = random_values\n",
    "\n",
    "        yield linked\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq = MCQGeneration('mh.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents,persons = mcq.ner_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "h = 0\n",
    "\n",
    "# Consume the generator and collect results\n",
    "for linked in mcq.search(documents, persons):  # Ensure `mcq` is defined and initialized\n",
    "    if h >= 1:  # Stop collecting after 10 outputs\n",
    "        break\n",
    "    all_results.append(linked)  # Append each yielded result to the list\n",
    "    h += 1\n",
    "\n",
    "# Print the results to verify\n",
    "print(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_trf\n",
    "from collections import defaultdict\n",
    "\n",
    "nlp = en_core_web_trf.load()\n",
    "\n",
    "# Load the pre-trained model\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "doc = nlp(data)\n",
    "words = defaultdict(set)\n",
    "for sent in doc.sents:\n",
    "    for ent in sent.ents:\n",
    "        words[ent.label_].add((ent.text,sent.text,ent.label_)) \n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_answers = []\n",
    "for key, value in words.items():\n",
    "    for i in words[key]:\n",
    "        context_answers.append(i)\n",
    "persons = [(i[1],i[0],i[2]) for i in context_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[2] for i in persons if i[1] == 'Santhal Pargana' for x in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Example: persons is a list of tuples [(context, ner_tag), ...]\n",
    "\n",
    "\n",
    "# Convert to Document objects\n",
    "documents = [\n",
    "    Document(page_content=context, metadata={\"ner_tag\": ner_tag,\"class\":label})\n",
    "    for context, ner_tag, label in persons\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "# Initialize embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "docsearch = Chroma.from_documents(documents, embeddings)\n",
    "\n",
    "print(\"Documents ingested successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "query = 'The burning of foreign cloth by Gandhi and the burning of Manusmriti by Ambedkar are not to be seen as mere acts of sentiment. Rather, foreign cloth and Manusmriti represented the bondage and slavery for India. So too, a pinch of salt from the ocean, and a drop of water from the Mahad tank were acts of political catharsis and social philosophy.'\n",
    "results = docsearch.similarity_search(query, k=50)  # Retrieve top-1 result\n",
    "\n",
    "for result in results:\n",
    "    print(\"Matched Context:\", result.page_content)\n",
    "    print(\"NER Tag:\", result.metadata.get(\"ner_tag\"))\n",
    "    print(\"NER label:\", result.metadata.get(\"class\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ('the Santhal Revolt',\n",
    "               'It was after the Santhal Revolt of 1855-56 that the Santhal Pargana was created out of the districts of Bhagalpur and Birbhum.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''Sher Singh was sent to suppress the revolt, but he himself joined Mulraj, leading to a mass uprising  in Multan.'''\n",
    "entity = example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from lmqg import TransformersQG\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "# initialize model\n",
    "model = TransformersQG(model='lmqg/t5-base-squad-qag') # or TransformersQG(model='lmqg/t5-base-squad-qg-ae') \n",
    "# paragraph to generate pairs of question and answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer = model.generate_qa(context)\n",
    "# the output is a list of tuple (question, answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = {}\n",
    "for i in question_answer:\n",
    "    linked.append(i)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in linked:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "for i in linked:\n",
    "    query=(i[0])\n",
    "    print(query)\n",
    "    ner = (i[1])\n",
    "    results = docsearch.similarity_search(query, k=5)  # Retrieve top-1 result\n",
    "    x = [j[2] for j in persons if j[1] == ner]\n",
    "    print(x)\n",
    "    options = []\n",
    "    for result in results:\n",
    "        if result.metadata.get(\"class\") in x and result.metadata.get(\"ner_tag\") not in options:\n",
    "            options.append(result.metadata.get(\"ner_tag\"))\n",
    "    all.append((query,ner,options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = []\n",
    "for i in all:\n",
    "    if i[2] != []:\n",
    "        valid.append(i)\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "output = []\n",
    "for question, correct_answer, options in valid:\n",
    "    # Remove the correct answer from options\n",
    "    filtered_options = [opt for opt in options if opt != correct_answer]\n",
    "    \n",
    "    # Randomly select 3 incorrect answers\n",
    "    random_choices = random.sample(filtered_options, 3)\n",
    "    \n",
    "    # Add the correct answer and shuffle\n",
    "    random_choices.append(correct_answer)\n",
    "    random.shuffle(random_choices)\n",
    "    \n",
    "    # Append formatted question set to output\n",
    "    output.append({\n",
    "        \"question\": question,\n",
    "        \"correctAnswer\": correct_answer,\n",
    "        \"options\": random_choices\n",
    "    })\n",
    "\n",
    "# Write to JSON file\n",
    "with open(\"questions.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[1] = 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[2] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys,values in r.items():\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,values in r.items():\n",
    "    for i in range(len(values)):\n",
    "        h = values\n",
    "        print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
